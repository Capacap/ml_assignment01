{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kravspecifikation fÃ¶r del 2\n",
    "\n",
    "1. âœ…Â BÃ¶rja anvÃ¤nda basala **MLOps best-practices:**\n",
    "    1. ðŸ“ŠÂ Ordna sÃ¥ att du har ett bra sÃ¤tt att Ã¶vervaka trÃ¤ningen, samt att spara (och hÃ¥lla ordning pÃ¥!) versioner av modellerna du trÃ¤nar upp. (Tips: Foldrar, smart valda filnamn, etc).\n",
    "    2. ðŸ’¾ Kom ihÃ¥g att det troligen inte Ã¤r den sista epokens checkpoint (sparad version) som Ã¤r den bÃ¤sta, p.g.a. overfitting om du kÃ¶r mÃ¥nga epochs. Du behÃ¶ver sjÃ¤lv se till att spara checkpoints lite dÃ¥ och dÃ¥ under trÃ¤ningen.\n",
    "    3. ðŸ—„ï¸Â Versionshantering av parametrar, kod, och checkpoints (modellens parametrar) blir snabbt vÃ¤ldigt viktigt nÃ¤r man bÃ¶rjar jobba seriÃ¶st med machine learning. Om man inte hÃ¥ller reda pÃ¥ vilken kÃ¶rning som gjorts med vilka parametrar, sÃ¥ blir det svÃ¥rt att jÃ¤mfÃ¶ra prestanda, vidareutveckla modellen senare, etc. Ingen vill ha en modell levererad dÃ¤r programmeraren inte minns hur den gjordes.\n",
    "    4. ðŸš€ **FÃ¶rdjupning/Ã¶verkurs:** Vilka verktyg finns som kan hjÃ¤lpa till att hÃ¥lla ordning pÃ¥ versioner, kÃ¶rningar, resultat, hyper parameters, etc?\n",
    "2. ðŸš€ **FÃ¶rdjupning/Ã¶verkurs:** Addera **performance metrics**, sÃ¥ att du kan se hur lÃ¥ng tid respektive trÃ¤nings-kÃ¶rning tar. (En kÃ¶rning = Alla epochs av trÃ¤ning fÃ¶r en given modell med specificerad uppsÃ¤ttning hyper parameters).\n",
    "3. âœ…Â Applicera lÃ¤mpliga **data augmentation** methods fÃ¶r att artificiellt variera, och till och med â€œfÃ¶rstoraâ€ datamÃ¤ngden lite. AnvÃ¤nd exempelvis skalning, rotation, fÃ¤rgvariation, brus, (spegelvÃ¤ndning?), etc. HÃ¤r Ã¤r lite repetition om data augmentation:\n",
    "    1. Se avsnittet â€œ[Uppgift 1 Perceptron foÌˆr OCR](https://www.notion.so/Uppgift-1-Perceptron-fo-r-OCR-d9e945f1551341e88665775acacc0bb6?pvs=21)â€ lÃ¤ngre ner i denna uppgift (del 3).\n",
    "    2. Bra 10-minuters video om Ã¤mnet: [Pytorch-Data-Augmentation-using-Torchvision](https://youtu.be/Zvd276j9sZ8?si=9fGaNnoRzsHrvxB6)\n",
    "    3. Observera att det inte Ã¤r sÃ¤kert att data augmentation leder till bÃ¤ttre resultat i alla lÃ¤gen, eftersom det beror pÃ¥ detaljerna i vad man bygger, och vilken data man har.\n",
    "4. âœ…Â Det Ã¤r nu dags att testa CNN istÃ¤llet fÃ¶r FFN. Byt ut de fÃ¶rsta lagren i modellen till **convolutional layers** fÃ¶r att ta upp translationsinvarians i bilden. SÃ¶k sjÃ¤lv upp vad man brukar ha ***direkt efter varje convolutional layer*** fÃ¶r att hÃ¥lla ordning pÃ¥ antalet dimensioner till nÃ¤sta lager .\n",
    "    \n",
    "    > (SvÃ¥rt ord â€œtranslations-invariansâ€: translation=fÃ¶rflyttning, invarians=â€samma oavsettâ€ â‡’ translationsinvarians = â€spelar ingen roll var i bildenâ€)\n",
    "    > \n",
    "5. âœ…Â Experimentera dÃ¤refter med att addera ett till (eller flera) convolutional layer(s). Tanken Ã¤r att testa **olika nÃ¤t-arkitekturer**. AnvÃ¤nd Google/Chat fÃ¶r initial gissning fÃ¶r modell-arkitektur, men sedan Ã¤r det trial-and-error som gÃ¤ller. Att fundera pÃ¥:\n",
    "    1. âš–ï¸ Hur pÃ¥verkas resultatet av olika modell-arkitektur? Var noga med att inte jÃ¤mfÃ¶ra modeller med stor skillnad i antal parameters, om aspekter som tex lagertyp ska utvÃ¤rderas.\n",
    "    2. ðŸ¤” Vilken typ av features detekteras typiskt av de senare convolutional-lagren jÃ¤mfÃ¶rt med det fÃ¶rsta convolutional-lagret?\n",
    "        1. Hint: Videon frÃ¥n lektion om convolutional layers: [Convolutional-Neural-Networks-Explained](https://youtu.be/pj9-rr1wDhM?si=cjWmR5ets048WjfZ). (SjÃ¤lvfallet kan du ocksÃ¥ plotta weight-matrices frÃ¥n din egen modell ocksÃ¥ om du vill!)\n",
    "6. âœ…Â Applicera lÃ¤mpliga **regularization methods** fÃ¶r att minimera risken fÃ¶r overfitting och gÃ¶ra cost-function-landskapet fÃ¶rdelaktigt fÃ¶r back-prop.\n",
    "    1. Exempel pÃ¥ sÃ¥dana metoder Ã¤r: drop-out, weight-decay, noise injection, batch normalization, etc.\n",
    "    2. Mer info om regularization: [understanding-regularization-with-pytorch](https://medium.com/analytics-vidhya/understanding-regularization-with-pytorch-26a838d94058)\n",
    "7. ðŸš€ **FÃ¶rdjupning:** Skapa en lista av kombinationer av hyper parameters, och lÃ¥t datorn trÃ¤na din modell pÃ¥ nytt fÃ¶r samtliga hyperparameter settings i din lista. Detta kallas fÃ¶r **hyper-parameter tuning**, d.v.s. att via trial-and-error hitta instÃ¤llningar som funkar.\n",
    "    - Enklast mÃ¶jliga hyper-param-tuning: GÃ¶r en lista med t.ex. 10 rader (en per kÃ¶rning), dÃ¤r varje rad specificerar alla hyper-parameters som kan vara svÃ¥rt att gissa optimalt vÃ¤rde pÃ¥:\n",
    "        - Antal neuroner fÃ¶r respektive lager\n",
    "        - Typ av activation function\n",
    "        - Vilka lager som ska vara convolutional, storlek pÃ¥ convolutional kernel, antal convolutional kernels per lager, etc.\n",
    "        - Learning rate / hyper-params till optimizer ADAM\n",
    "        - Drop-out level\n",
    "        - Settings fÃ¶r olika typer av data augmentation (rotation, skalning, noise, etc)\n",
    "    - Det finns Ã¤ven en mÃ¤ngd automatiserade typer av hyper-param-tuning. Se exempelvis: https://en.wikipedia.org/wiki/Hyperparameter_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the perceptron neural-network model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Perceptron(nn.Module):\n",
    "    # Define the constructor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Flatten the input\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Define the layers with ReLU activation function\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            # Input layer   \n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Hidden layer\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Output layer\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    # Define the forward pass\n",
    "    def forward(self, x):\n",
    "        # Flatten the input\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # Pass through the layers\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "\n",
      "Perceptron(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\\n\")\n",
    "\n",
    "model = Perceptron().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MNIST dataset and create dataloaders\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformations for training data as data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),  # Rotate by up to 10 degrees\n",
    "    transforms.RandomAffine(0, scale=(0.8, 1.2)),  # Random scaling\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),  # Normalize with MNIST mean/std (pre-computed)\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "# Transformations for test data (no augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 20:08:13,906 - INFO - --------------------------------------------------------------------------------\n",
      "2025-04-16 20:08:13,907 - INFO - Epoch 1:\n",
      "2025-04-16 20:08:13,937 - INFO -     [   64/60000] - Loss: 2.961130\n",
      "2025-04-16 20:08:15,368 - INFO -     [ 6464/60000] - Loss: 0.207177\n",
      "2025-04-16 20:08:16,815 - INFO -     [12864/60000] - Loss: 0.249086\n",
      "2025-04-16 20:08:18,262 - INFO -     [19264/60000] - Loss: 0.064662\n",
      "2025-04-16 20:08:19,670 - INFO -     [25664/60000] - Loss: 0.186498\n",
      "2025-04-16 20:08:21,064 - INFO -     [32064/60000] - Loss: 0.248541\n",
      "2025-04-16 20:08:22,472 - INFO -     [38464/60000] - Loss: 0.069734\n",
      "2025-04-16 20:08:23,883 - INFO -     [44864/60000] - Loss: 0.031699\n",
      "2025-04-16 20:08:25,285 - INFO -     [51264/60000] - Loss: 0.080397\n",
      "2025-04-16 20:08:26,678 - INFO -     [57664/60000] - Loss: 0.076674\n",
      "2025-04-16 20:08:28,390 - INFO -     Test accuracy: 98.33\n",
      "2025-04-16 20:08:28,390 - INFO -     Test avg loss: 0.053572002546301935\n",
      "2025-04-16 20:08:28,400 - INFO -     Checkpoint saved to models/run_20250416_200813/checkpoint_epoch_1.pt\n",
      "2025-04-16 20:08:28,400 - INFO -     Training time: 13.28 seconds\n",
      "2025-04-16 20:08:28,401 - INFO -     Testing time: 1.20 seconds\n",
      "2025-04-16 20:08:28,401 - INFO -     Total epoch time: 14.48 seconds\n",
      "2025-04-16 20:08:28,401 - INFO - --------------------------------------------------------------------------------\n",
      "2025-04-16 20:08:28,402 - INFO - Epoch 2:\n",
      "2025-04-16 20:08:28,418 - INFO -     [   64/60000] - Loss: 0.017376\n",
      "2025-04-16 20:08:29,825 - INFO -     [ 6464/60000] - Loss: 0.132045\n",
      "2025-04-16 20:08:31,232 - INFO -     [12864/60000] - Loss: 0.013177\n",
      "2025-04-16 20:08:32,627 - INFO -     [19264/60000] - Loss: 0.083324\n",
      "2025-04-16 20:08:34,031 - INFO -     [25664/60000] - Loss: 0.017966\n",
      "2025-04-16 20:08:35,480 - INFO -     [32064/60000] - Loss: 0.097037\n",
      "2025-04-16 20:08:36,908 - INFO -     [38464/60000] - Loss: 0.032119\n",
      "2025-04-16 20:08:38,352 - INFO -     [44864/60000] - Loss: 0.031036\n",
      "2025-04-16 20:08:39,771 - INFO -     [51264/60000] - Loss: 0.287742\n",
      "2025-04-16 20:08:41,209 - INFO -     [57664/60000] - Loss: 0.016812\n",
      "2025-04-16 20:08:42,934 - INFO -     Test accuracy: 98.16\n",
      "2025-04-16 20:08:42,934 - INFO -     Test avg loss: 0.06394991598665384\n",
      "2025-04-16 20:08:42,945 - INFO -     Checkpoint saved to models/run_20250416_200813/checkpoint_epoch_2.pt\n",
      "2025-04-16 20:08:42,945 - INFO -     Training time: 13.32 seconds\n",
      "2025-04-16 20:08:42,946 - INFO -     Testing time: 1.21 seconds\n",
      "2025-04-16 20:08:42,946 - INFO -     Total epoch time: 14.53 seconds\n",
      "2025-04-16 20:08:42,946 - INFO - --------------------------------------------------------------------------------\n",
      "2025-04-16 20:08:42,947 - INFO - Epoch 3:\n",
      "2025-04-16 20:08:42,964 - INFO -     [   64/60000] - Loss: 0.074746\n",
      "2025-04-16 20:08:44,361 - INFO -     [ 6464/60000] - Loss: 0.116048\n",
      "2025-04-16 20:08:45,776 - INFO -     [12864/60000] - Loss: 0.106842\n",
      "2025-04-16 20:08:47,167 - INFO -     [19264/60000] - Loss: 0.130597\n",
      "2025-04-16 20:08:48,562 - INFO -     [25664/60000] - Loss: 0.038226\n",
      "2025-04-16 20:08:49,953 - INFO -     [32064/60000] - Loss: 0.131712\n",
      "2025-04-16 20:08:51,357 - INFO -     [38464/60000] - Loss: 0.032157\n",
      "2025-04-16 20:08:52,764 - INFO -     [44864/60000] - Loss: 0.024570\n",
      "2025-04-16 20:08:54,156 - INFO -     [51264/60000] - Loss: 0.019724\n",
      "2025-04-16 20:08:55,550 - INFO -     [57664/60000] - Loss: 0.159657\n",
      "2025-04-16 20:08:57,259 - INFO -     Test accuracy: 98.0\n",
      "2025-04-16 20:08:57,259 - INFO -     Test avg loss: 0.06371075124637399\n",
      "2025-04-16 20:08:57,269 - INFO -     Checkpoint saved to models/run_20250416_200813/checkpoint_epoch_3.pt\n",
      "2025-04-16 20:08:57,269 - INFO -     Training time: 13.12 seconds\n",
      "2025-04-16 20:08:57,270 - INFO -     Testing time: 1.20 seconds\n",
      "2025-04-16 20:08:57,270 - INFO -     Total epoch time: 14.31 seconds\n",
      "2025-04-16 20:08:57,271 - INFO - --------------------------------------------------------------------------------\n",
      "2025-04-16 20:08:57,271 - INFO - Epoch 4:\n",
      "2025-04-16 20:08:57,287 - INFO -     [   64/60000] - Loss: 0.087285\n",
      "2025-04-16 20:08:58,684 - INFO -     [ 6464/60000] - Loss: 0.059478\n",
      "2025-04-16 20:09:00,083 - INFO -     [12864/60000] - Loss: 0.041064\n",
      "2025-04-16 20:09:01,476 - INFO -     [19264/60000] - Loss: 0.035029\n",
      "2025-04-16 20:09:02,865 - INFO -     [25664/60000] - Loss: 0.167143\n",
      "2025-04-16 20:09:04,256 - INFO -     [32064/60000] - Loss: 0.048452\n",
      "2025-04-16 20:09:05,669 - INFO -     [38464/60000] - Loss: 0.135229\n",
      "2025-04-16 20:09:07,100 - INFO -     [44864/60000] - Loss: 0.028089\n",
      "2025-04-16 20:09:08,518 - INFO -     [51264/60000] - Loss: 0.097079\n",
      "2025-04-16 20:09:09,927 - INFO -     [57664/60000] - Loss: 0.252708\n",
      "2025-04-16 20:09:11,647 - INFO -     Test accuracy: 98.16\n",
      "2025-04-16 20:09:11,648 - INFO -     Test avg loss: 0.06272702218706933\n",
      "2025-04-16 20:09:11,657 - INFO -     Checkpoint saved to models/run_20250416_200813/checkpoint_epoch_4.pt\n",
      "2025-04-16 20:09:11,658 - INFO -     Training time: 13.17 seconds\n",
      "2025-04-16 20:09:11,658 - INFO -     Testing time: 1.21 seconds\n",
      "2025-04-16 20:09:11,658 - INFO -     Total epoch time: 14.38 seconds\n",
      "2025-04-16 20:09:11,659 - INFO - --------------------------------------------------------------------------------\n",
      "2025-04-16 20:09:11,659 - INFO - Epoch 5:\n",
      "2025-04-16 20:09:11,676 - INFO -     [   64/60000] - Loss: 0.049683\n",
      "2025-04-16 20:09:13,085 - INFO -     [ 6464/60000] - Loss: 0.049854\n",
      "2025-04-16 20:09:14,514 - INFO -     [12864/60000] - Loss: 0.026215\n",
      "2025-04-16 20:09:15,926 - INFO -     [19264/60000] - Loss: 0.049687\n",
      "2025-04-16 20:09:17,320 - INFO -     [25664/60000] - Loss: 0.031492\n",
      "2025-04-16 20:09:18,787 - INFO -     [32064/60000] - Loss: 0.068280\n",
      "2025-04-16 20:09:20,188 - INFO -     [38464/60000] - Loss: 0.069871\n",
      "2025-04-16 20:09:21,593 - INFO -     [44864/60000] - Loss: 0.134689\n",
      "2025-04-16 20:09:23,000 - INFO -     [51264/60000] - Loss: 0.069890\n",
      "2025-04-16 20:09:24,442 - INFO -     [57664/60000] - Loss: 0.237632\n",
      "2025-04-16 20:09:26,161 - INFO -     Test accuracy: 98.2\n",
      "2025-04-16 20:09:26,161 - INFO -     Test avg loss: 0.05919031898501651\n",
      "2025-04-16 20:09:26,171 - INFO -     Checkpoint saved to models/run_20250416_200813/checkpoint_epoch_5.pt\n",
      "2025-04-16 20:09:26,172 - INFO -     Training time: 13.30 seconds\n",
      "2025-04-16 20:09:26,172 - INFO -     Testing time: 1.20 seconds\n",
      "2025-04-16 20:09:26,173 - INFO -     Total epoch time: 14.50 seconds\n",
      "2025-04-16 20:09:26,173 - INFO - --------------------------------------------------------------------------------\n",
      "2025-04-16 20:09:26,174 - INFO - Training complete!\n",
      "2025-04-16 20:09:26,174 - INFO - Total training time: 72.27 seconds\n",
      "2025-04-16 20:09:26,174 - INFO - Best epoch: 1\n",
      "2025-04-16 20:09:26,175 - INFO - --------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the network using ADAM back-propagation\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "\n",
    "# Generate a unique run ID for this experiment and create a directory for it\n",
    "os.makedirs('models', exist_ok=True)\n",
    "run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_dir = os.path.join('models', f'run_{run_id}')\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "# Configure logging and create a logger object and log file\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "log_file = os.path.join(run_dir, 'training.log')\n",
    "fhandler = logging.FileHandler(filename=log_file, mode='a')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "\n",
    "# Define hyperparameters\n",
    "hyperparams = {\n",
    "    'learning_rate': 0.001,\n",
    "    'num_epochs': 5,\n",
    "}\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=hyperparams['learning_rate'])\n",
    "\n",
    "# Save hyperparameters for versioning\n",
    "with open(os.path.join(run_dir, 'hyperparams.json'), 'w') as f:\n",
    "    json.dump(hyperparams, f, indent=4)\n",
    "\n",
    "# Training loop\n",
    "def train():\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(pred.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            logger.info(f\"    [{current:>5d}/{len(train_dataloader.dataset):>5d}] - Loss: {loss:>7f}\")\n",
    "\n",
    "    return train_loss / len(train_dataloader)\n",
    "\n",
    "# Test loop\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            \n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            _, predicted = torch.max(pred.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "\n",
    "    logger.info(f\"    Test accuracy: {test_accuracy}\")\n",
    "    logger.info(f\"    Test avg loss: {test_loss}\")\n",
    "\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "# Save model checkpoint\n",
    "def save_checkpoint(epoch, file_path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'hyperparams': hyperparams\n",
    "    }\n",
    "    \n",
    "    # Save checkpoint\n",
    "    torch.save(checkpoint, file_path)\n",
    "    logger.info(f\"    Checkpoint saved to {file_path}\")\n",
    "\n",
    "# Train the model\n",
    "total_start_time = time.time()\n",
    "best_accuracy = 0\n",
    "best_epoch = 1\n",
    "\n",
    "logger.info(\"-\" * 80)\n",
    "for epoch in range(hyperparams['num_epochs']):\n",
    "    logger.info(f\"Epoch {epoch+1}:\")\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    # Training phase\n",
    "    train_start_time = time.time()\n",
    "    train_loss = train()\n",
    "    train_elapsed_time = time.time() - train_start_time\n",
    "\n",
    "    # Testing phase\n",
    "    test_start_time = time.time()\n",
    "    test_loss, test_accuracy = test()\n",
    "    test_elapsed_time = time.time() - test_start_time\n",
    "\n",
    "    epoch_elapsed_time = time.time() - epoch_start_time\n",
    "\n",
    "    # Update best accuracy and epoch\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        best_epoch = epoch + 1\n",
    "\n",
    "    # Save checkpoint to file\n",
    "    save_checkpoint(epoch, os.path.join(run_dir, f'checkpoint_epoch_{epoch+1}.pt'))\n",
    "\n",
    "    # Log epoch results\n",
    "    logger.info(f\"    Training time: {train_elapsed_time:.2f} seconds\")\n",
    "    logger.info(f\"    Testing time: {test_elapsed_time:.2f} seconds\")\n",
    "    logger.info(f\"    Total epoch time: {epoch_elapsed_time:.2f} seconds\")\n",
    "    logger.info(\"-\" * 80)\n",
    "\n",
    "# Log total training time and best epoch\n",
    "total_elapsed_time = time.time() - total_start_time\n",
    "logger.info(\"Training complete!\")\n",
    "logger.info(f\"Total training time: {total_elapsed_time:.2f} seconds\")\n",
    "logger.info(f\"Best epoch: {best_epoch}\")\n",
    "logger.info(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
