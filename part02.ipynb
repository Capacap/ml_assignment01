{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kravspecifikation f√∂r del 2\n",
    "\n",
    "1. ‚úÖ¬†B√∂rja anv√§nda basala **MLOps best-practices:**\n",
    "    1. üìä¬†Ordna s√• att du har ett bra s√§tt att √∂vervaka tr√§ningen, samt att spara (och h√•lla ordning p√•!) versioner av modellerna du tr√§nar upp. (Tips: Foldrar, smart valda filnamn, etc).\n",
    "    2. üíæ Kom ih√•g att det troligen inte √§r den sista epokens checkpoint (sparad version) som √§r den b√§sta, p.g.a. overfitting om du k√∂r m√•nga epochs. Du beh√∂ver sj√§lv se till att spara checkpoints lite d√• och d√• under tr√§ningen.\n",
    "    3. üóÑÔ∏è¬†Versionshantering av parametrar, kod, och checkpoints (modellens parametrar) blir snabbt v√§ldigt viktigt n√§r man b√∂rjar jobba seri√∂st med machine learning. Om man inte h√•ller reda p√• vilken k√∂rning som gjorts med vilka parametrar, s√• blir det sv√•rt att j√§mf√∂ra prestanda, vidareutveckla modellen senare, etc. Ingen vill ha en modell levererad d√§r programmeraren inte minns hur den gjordes.\n",
    "    4. üöÄ **F√∂rdjupning/√∂verkurs:** Vilka verktyg finns som kan hj√§lpa till att h√•lla ordning p√• versioner, k√∂rningar, resultat, hyper parameters, etc?\n",
    "2. üöÄ **F√∂rdjupning/√∂verkurs:** Addera **performance metrics**, s√• att du kan se hur l√•ng tid respektive tr√§nings-k√∂rning tar. (En k√∂rning = Alla epochs av tr√§ning f√∂r en given modell med specificerad upps√§ttning hyper parameters).\n",
    "3. ‚úÖ¬†Applicera l√§mpliga **data augmentation** methods f√∂r att artificiellt variera, och till och med ‚Äúf√∂rstora‚Äù datam√§ngden lite. Anv√§nd exempelvis skalning, rotation, f√§rgvariation, brus, (spegelv√§ndning?), etc. H√§r √§r lite repetition om data augmentation:\n",
    "    1. Se avsnittet ‚Äú[Uppgift 1 Perceptron foÃàr OCR](https://www.notion.so/Uppgift-1-Perceptron-fo-r-OCR-d9e945f1551341e88665775acacc0bb6?pvs=21)‚Äù l√§ngre ner i denna uppgift (del 3).\n",
    "    2. Bra 10-minuters video om √§mnet: [Pytorch-Data-Augmentation-using-Torchvision](https://youtu.be/Zvd276j9sZ8?si=9fGaNnoRzsHrvxB6)\n",
    "    3. Observera att det inte √§r s√§kert att data augmentation leder till b√§ttre resultat i alla l√§gen, eftersom det beror p√• detaljerna i vad man bygger, och vilken data man har.\n",
    "4. ‚úÖ¬†Det √§r nu dags att testa CNN ist√§llet f√∂r FFN. Byt ut de f√∂rsta lagren i modellen till **convolutional layers** f√∂r att ta upp translationsinvarians i bilden. S√∂k sj√§lv upp vad man brukar ha ***direkt efter varje convolutional layer*** f√∂r att h√•lla ordning p√• antalet dimensioner till n√§sta lager .\n",
    "    \n",
    "    > (Sv√•rt ord ‚Äútranslations-invarians‚Äù: translation=f√∂rflyttning, invarians=‚Äùsamma oavsett‚Äù ‚áí translationsinvarians = ‚Äùspelar ingen roll var i bilden‚Äù)\n",
    "    > \n",
    "5. ‚úÖ¬†Experimentera d√§refter med att addera ett till (eller flera) convolutional layer(s). Tanken √§r att testa **olika n√§t-arkitekturer**. Anv√§nd Google/Chat f√∂r initial gissning f√∂r modell-arkitektur, men sedan √§r det trial-and-error som g√§ller. Att fundera p√•:\n",
    "    1. ‚öñÔ∏è Hur p√•verkas resultatet av olika modell-arkitektur? Var noga med att inte j√§mf√∂ra modeller med stor skillnad i antal parameters, om aspekter som tex lagertyp ska utv√§rderas.\n",
    "    2. ü§î Vilken typ av features detekteras typiskt av de senare convolutional-lagren j√§mf√∂rt med det f√∂rsta convolutional-lagret?\n",
    "        1. Hint: Videon fr√•n lektion om convolutional layers: [Convolutional-Neural-Networks-Explained](https://youtu.be/pj9-rr1wDhM?si=cjWmR5ets048WjfZ). (Sj√§lvfallet kan du ocks√• plotta weight-matrices fr√•n din egen modell ocks√• om du vill!)\n",
    "6. ‚úÖ¬†Applicera l√§mpliga **regularization methods** f√∂r att minimera risken f√∂r overfitting och g√∂ra cost-function-landskapet f√∂rdelaktigt f√∂r back-prop.\n",
    "    1. Exempel p√• s√•dana metoder √§r: drop-out, weight-decay, noise injection, batch normalization, etc.\n",
    "    2. Mer info om regularization: [understanding-regularization-with-pytorch](https://medium.com/analytics-vidhya/understanding-regularization-with-pytorch-26a838d94058)\n",
    "7. üöÄ **F√∂rdjupning:** Skapa en lista av kombinationer av hyper parameters, och l√•t datorn tr√§na din modell p√• nytt f√∂r samtliga hyperparameter settings i din lista. Detta kallas f√∂r **hyper-parameter tuning**, d.v.s. att via trial-and-error hitta inst√§llningar som funkar.\n",
    "    - Enklast m√∂jliga hyper-param-tuning: G√∂r en lista med t.ex. 10 rader (en per k√∂rning), d√§r varje rad specificerar alla hyper-parameters som kan vara sv√•rt att gissa optimalt v√§rde p√•:\n",
    "        - Antal neuroner f√∂r respektive lager\n",
    "        - Typ av activation function\n",
    "        - Vilka lager som ska vara convolutional, storlek p√• convolutional kernel, antal convolutional kernels per lager, etc.\n",
    "        - Learning rate / hyper-params till optimizer ADAM\n",
    "        - Drop-out level\n",
    "        - Settings f√∂r olika typer av data augmentation (rotation, skalning, noise, etc)\n",
    "    - Det finns √§ven en m√§ngd automatiserade typer av hyper-param-tuning. Se exempelvis: https://en.wikipedia.org/wiki/Hyperparameter_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the perceptron neural-network model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Perceptron(nn.Module):\n",
    "    # Define the constructor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Flatten the input\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Define the layers with ReLU activation function\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            # Input layer   \n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Hidden layer\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Output layer\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    # Define the forward pass\n",
    "    def forward(self, x):\n",
    "        # Flatten the input\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # Pass through the layers\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "\n",
      "Perceptron(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\\n\")\n",
    "\n",
    "model = Perceptron().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MNIST dataset and create dataloaders\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformations for training data as data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),  # Rotate by up to 10 degrees\n",
    "    transforms.RandomAffine(0, scale=(0.8, 1.2)),  # Random scaling\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),  # Normalize with MNIST mean/std (pre-computed)\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "# Transformations for test data (no augmentation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 20:08:13,906 - INFO - --------------------------------------------------------------------------------\n",
      "2025-04-16 20:08:13,907 - INFO - Epoch 1:\n",
      "2025-04-16 20:08:13,937 - INFO -     [   64/60000] - Loss: 2.961130\n",
      "2025-04-16 20:08:15,368 - INFO -     [ 6464/60000] - Loss: 0.207177\n",
      "2025-04-16 20:08:16,815 - INFO -     [12864/60000] - Loss: 0.249086\n",
      "2025-04-16 20:08:18,262 - INFO -     [19264/60000] - Loss: 0.064662\n",
      "2025-04-16 20:08:19,670 - INFO -     [25664/60000] - Loss: 0.186498\n",
      "2025-04-16 20:08:21,064 - INFO -     [32064/60000] - Loss: 0.248541\n",
      "2025-04-16 20:08:22,472 - INFO -     [38464/60000] - Loss: 0.069734\n",
      "2025-04-16 20:08:23,883 - INFO -     [44864/60000] - Loss: 0.031699\n",
      "2025-04-16 20:08:25,285 - INFO -     [51264/60000] - Loss: 0.080397\n",
      "2025-04-16 20:08:26,678 - INFO -     [57664/60000] - Loss: 0.076674\n",
      "2025-04-16 20:08:28,390 - INFO -     Test accuracy: 98.33\n",
      "2025-04-16 20:08:28,390 - INFO -     Test avg loss: 0.053572002546301935\n",
      "2025-04-16 20:08:28,400 - INFO -     Checkpoint saved to models/run_20250416_200813/checkpoint_epoch_1.pt\n",
      "2025-04-16 20:08:28,400 - INFO -     Training time: 13.28 seconds\n",
      "2025-04-16 20:08:28,401 - INFO -     Testing time: 1.20 seconds\n",
      "2025-04-16 20:08:28,401 - INFO -     Total epoch time: 14.48 seconds\n",
      "2025-04-16 20:08:28,401 - INFO - --------------------------------------------------------------------------------\n",
      "2025-04-16 20:08:28,402 - INFO - Epoch 2:\n",
      "2025-04-16 20:08:28,418 - INFO -     [   64/60000] - Loss: 0.017376\n",
      "2025-04-16 20:08:29,825 - INFO -     [ 6464/60000] - Loss: 0.132045\n",
      "2025-04-16 20:08:31,232 - INFO -     [12864/60000] - Loss: 0.013177\n",
      "2025-04-16 20:08:32,627 - INFO -     [19264/60000] - Loss: 0.083324\n",
      "2025-04-16 20:08:34,031 - INFO -     [25664/60000] - Loss: 0.017966\n",
      "2025-04-16 20:08:35,480 - INFO -     [32064/60000] - Loss: 0.097037\n",
      "2025-04-16 20:08:36,908 - INFO -     [38464/60000] - Loss: 0.032119\n",
      "2025-04-16 20:08:38,352 - INFO -     [44864/60000] - Loss: 0.031036\n",
      "2025-04-16 20:08:39,771 - INFO -     [51264/60000] - Loss: 0.287742\n",
      "2025-04-16 20:08:41,209 - INFO -     [57664/60000] - Loss: 0.016812\n",
      "2025-04-16 20:08:42,934 - INFO -     Test accuracy: 98.16\n",
      "2025-04-16 20:08:42,934 - INFO -     Test avg loss: 0.06394991598665384\n",
      "2025-04-16 20:08:42,945 - INFO -     Checkpoint saved to models/run_20250416_200813/checkpoint_epoch_2.pt\n",
      "2025-04-16 20:08:42,945 - INFO -     Training time: 13.32 seconds\n",
      "2025-04-16 20:08:42,946 - INFO -     Testing time: 1.21 seconds\n",
      "2025-04-16 20:08:42,946 - INFO -     Total epoch time: 14.53 seconds\n",
      "2025-04-16 20:08:42,946 - INFO - --------------------------------------------------------------------------------\n",
      "2025-04-16 20:08:42,947 - INFO - Epoch 3:\n",
      "2025-04-16 20:08:42,964 - INFO -     [   64/60000] - Loss: 0.074746\n",
      "2025-04-16 20:08:44,361 - INFO -     [ 6464/60000] - Loss: 0.116048\n",
      "2025-04-16 20:08:45,776 - INFO -     [12864/60000] - Loss: 0.106842\n",
      "2025-04-16 20:08:47,167 - INFO -     [19264/60000] - Loss: 0.130597\n",
      "2025-04-16 20:08:48,562 - INFO -     [25664/60000] - Loss: 0.038226\n",
      "2025-04-16 20:08:49,953 - INFO -     [32064/60000] - Loss: 0.131712\n",
      "2025-04-16 20:08:51,357 - INFO -     [38464/60000] - Loss: 0.032157\n",
      "2025-04-16 20:08:52,764 - INFO -     [44864/60000] - Loss: 0.024570\n",
      "2025-04-16 20:08:54,156 - INFO -     [51264/60000] - Loss: 0.019724\n",
      "2025-04-16 20:08:55,550 - INFO -     [57664/60000] - Loss: 0.159657\n",
      "2025-04-16 20:08:57,259 - INFO -     Test accuracy: 98.0\n",
      "2025-04-16 20:08:57,259 - INFO -     Test avg loss: 0.06371075124637399\n",
      "2025-04-16 20:08:57,269 - INFO -     Checkpoint saved to models/run_20250416_200813/checkpoint_epoch_3.pt\n",
      "2025-04-16 20:08:57,269 - INFO -     Training time: 13.12 seconds\n",
      "2025-04-16 20:08:57,270 - INFO -     Testing time: 1.20 seconds\n",
      "2025-04-16 20:08:57,270 - INFO -     Total epoch time: 14.31 seconds\n",
      "2025-04-16 20:08:57,271 - INFO - --------------------------------------------------------------------------------\n",
      "2025-04-16 20:08:57,271 - INFO - Epoch 4:\n",
      "2025-04-16 20:08:57,287 - INFO -     [   64/60000] - Loss: 0.087285\n",
      "2025-04-16 20:08:58,684 - INFO -     [ 6464/60000] - Loss: 0.059478\n",
      "2025-04-16 20:09:00,083 - INFO -     [12864/60000] - Loss: 0.041064\n",
      "2025-04-16 20:09:01,476 - INFO -     [19264/60000] - Loss: 0.035029\n",
      "2025-04-16 20:09:02,865 - INFO -     [25664/60000] - Loss: 0.167143\n",
      "2025-04-16 20:09:04,256 - INFO -     [32064/60000] - Loss: 0.048452\n",
      "2025-04-16 20:09:05,669 - INFO -     [38464/60000] - Loss: 0.135229\n",
      "2025-04-16 20:09:07,100 - INFO -     [44864/60000] - Loss: 0.028089\n",
      "2025-04-16 20:09:08,518 - INFO -     [51264/60000] - Loss: 0.097079\n",
      "2025-04-16 20:09:09,927 - INFO -     [57664/60000] - Loss: 0.252708\n",
      "2025-04-16 20:09:11,647 - INFO -     Test accuracy: 98.16\n",
      "2025-04-16 20:09:11,648 - INFO -     Test avg loss: 0.06272702218706933\n",
      "2025-04-16 20:09:11,657 - INFO -     Checkpoint saved to models/run_20250416_200813/checkpoint_epoch_4.pt\n",
      "2025-04-16 20:09:11,658 - INFO -     Training time: 13.17 seconds\n",
      "2025-04-16 20:09:11,658 - INFO -     Testing time: 1.21 seconds\n",
      "2025-04-16 20:09:11,658 - INFO -     Total epoch time: 14.38 seconds\n",
      "2025-04-16 20:09:11,659 - INFO - --------------------------------------------------------------------------------\n",
      "2025-04-16 20:09:11,659 - INFO - Epoch 5:\n",
      "2025-04-16 20:09:11,676 - INFO -     [   64/60000] - Loss: 0.049683\n",
      "2025-04-16 20:09:13,085 - INFO -     [ 6464/60000] - Loss: 0.049854\n",
      "2025-04-16 20:09:14,514 - INFO -     [12864/60000] - Loss: 0.026215\n",
      "2025-04-16 20:09:15,926 - INFO -     [19264/60000] - Loss: 0.049687\n",
      "2025-04-16 20:09:17,320 - INFO -     [25664/60000] - Loss: 0.031492\n",
      "2025-04-16 20:09:18,787 - INFO -     [32064/60000] - Loss: 0.068280\n",
      "2025-04-16 20:09:20,188 - INFO -     [38464/60000] - Loss: 0.069871\n",
      "2025-04-16 20:09:21,593 - INFO -     [44864/60000] - Loss: 0.134689\n",
      "2025-04-16 20:09:23,000 - INFO -     [51264/60000] - Loss: 0.069890\n",
      "2025-04-16 20:09:24,442 - INFO -     [57664/60000] - Loss: 0.237632\n",
      "2025-04-16 20:09:26,161 - INFO -     Test accuracy: 98.2\n",
      "2025-04-16 20:09:26,161 - INFO -     Test avg loss: 0.05919031898501651\n",
      "2025-04-16 20:09:26,171 - INFO -     Checkpoint saved to models/run_20250416_200813/checkpoint_epoch_5.pt\n",
      "2025-04-16 20:09:26,172 - INFO -     Training time: 13.30 seconds\n",
      "2025-04-16 20:09:26,172 - INFO -     Testing time: 1.20 seconds\n",
      "2025-04-16 20:09:26,173 - INFO -     Total epoch time: 14.50 seconds\n",
      "2025-04-16 20:09:26,173 - INFO - --------------------------------------------------------------------------------\n",
      "2025-04-16 20:09:26,174 - INFO - Training complete!\n",
      "2025-04-16 20:09:26,174 - INFO - Total training time: 72.27 seconds\n",
      "2025-04-16 20:09:26,174 - INFO - Best epoch: 1\n",
      "2025-04-16 20:09:26,175 - INFO - --------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the network using ADAM back-propagation\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "\n",
    "# Generate a unique run ID for this experiment and create a directory for it\n",
    "os.makedirs('models', exist_ok=True)\n",
    "run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_dir = os.path.join('models', f'run_{run_id}')\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "# Configure logging and create a logger object and log file\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "log_file = os.path.join(run_dir, 'training.log')\n",
    "fhandler = logging.FileHandler(filename=log_file, mode='a')\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "\n",
    "# Define hyperparameters\n",
    "hyperparams = {\n",
    "    'learning_rate': 0.001,\n",
    "    'num_epochs': 5,\n",
    "}\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=hyperparams['learning_rate'])\n",
    "\n",
    "# Save hyperparameters for versioning\n",
    "with open(os.path.join(run_dir, 'hyperparams.json'), 'w') as f:\n",
    "    json.dump(hyperparams, f, indent=4)\n",
    "\n",
    "# Training loop\n",
    "def train():\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(pred.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            logger.info(f\"    [{current:>5d}/{len(train_dataloader.dataset):>5d}] - Loss: {loss:>7f}\")\n",
    "\n",
    "    return train_loss / len(train_dataloader)\n",
    "\n",
    "# Test loop\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            \n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            _, predicted = torch.max(pred.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "\n",
    "    logger.info(f\"    Test accuracy: {test_accuracy}\")\n",
    "    logger.info(f\"    Test avg loss: {test_loss}\")\n",
    "\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "# Save model checkpoint\n",
    "def save_checkpoint(epoch, file_path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'hyperparams': hyperparams\n",
    "    }\n",
    "    \n",
    "    # Save checkpoint\n",
    "    torch.save(checkpoint, file_path)\n",
    "    logger.info(f\"    Checkpoint saved to {file_path}\")\n",
    "\n",
    "# Train the model\n",
    "total_start_time = time.time()\n",
    "best_accuracy = 0\n",
    "best_epoch = 1\n",
    "\n",
    "logger.info(\"-\" * 80)\n",
    "for epoch in range(hyperparams['num_epochs']):\n",
    "    logger.info(f\"Epoch {epoch+1}:\")\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    # Training phase\n",
    "    train_start_time = time.time()\n",
    "    train_loss = train()\n",
    "    train_elapsed_time = time.time() - train_start_time\n",
    "\n",
    "    # Testing phase\n",
    "    test_start_time = time.time()\n",
    "    test_loss, test_accuracy = test()\n",
    "    test_elapsed_time = time.time() - test_start_time\n",
    "\n",
    "    epoch_elapsed_time = time.time() - epoch_start_time\n",
    "\n",
    "    # Update best accuracy and epoch\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        best_epoch = epoch + 1\n",
    "\n",
    "    # Save checkpoint to file\n",
    "    save_checkpoint(epoch, os.path.join(run_dir, f'checkpoint_epoch_{epoch+1}.pt'))\n",
    "\n",
    "    # Log epoch results\n",
    "    logger.info(f\"    Training time: {train_elapsed_time:.2f} seconds\")\n",
    "    logger.info(f\"    Testing time: {test_elapsed_time:.2f} seconds\")\n",
    "    logger.info(f\"    Total epoch time: {epoch_elapsed_time:.2f} seconds\")\n",
    "    logger.info(\"-\" * 80)\n",
    "\n",
    "# Log total training time and best epoch\n",
    "total_elapsed_time = time.time() - total_start_time\n",
    "logger.info(\"Training complete!\")\n",
    "logger.info(f\"Total training time: {total_elapsed_time:.2f} seconds\")\n",
    "logger.info(f\"Best epoch: {best_epoch}\")\n",
    "logger.info(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
